---
title: Hadoop之分布式文件系统—HDFS（1）
tags: HDFS,IO,Map Reduce
---

虽然现在业内用Hadoop自带的Map Reduce来处理数据的已经不是很多了，但还是用Hadoop的分布式存储系统HDFS结合Spark来处理大数据。所以这里先分享我所学习的有关HDFS的知识。


## HDFS简介
__自从Hadoop问世以后，它的文件存储机制就成为了一种虚拟化存储中的经典。这就是HDFS。HDFS是Hadoop的最高级文件存储系统，包含了其自身特有的文件存储机制、本地文件系统和Amazon S3等优秀的系统。__

## HDFS的特点
__1.少存储，多读取。减少写入次数，即一次写入大量数据；然后分多次读取数据，把更多的时间留给对数据的处理上。__
__2.Hadoop的硬件基础往往是便宜的普通零件，而不是特别高质量的硬件组，所以硬件的损坏还是很可观的。但是HDFS又被设计成了具有较高容能力的虚拟化系统。__
__3.HDFS牺牲了一定的时间来换取了较高的吞吐率，所以它的数据访问速度不如Hive和HBase。__
__4.HDFS的存储块很大，至少大到物理磁盘的100多倍。这使得HDFS在节省存储空间、寻找数据地址的能力有了一定的提升。__
__5.HDFS在大文件上的优势要远远大于小文件。如果小文件的数量足够大，那么在HDFS管理下很有可能硬件设备就不满足了需求了。__
__6.单用户管理写入和修改，多用户读取数据。__

## HDFS的数据分块
__HDFS主要处理大数据，这个数据量非常大，以至于如果按照普通的文件系统分块方法，会极大地增加数据寻找时间，这在效率上会带来弊端。所以HDFS的默认块大小是64MB，当然可以提升至更高。但是由于HDFS处理数据是按块读取，块空间过大，块数量就会过少，这样处理效率也会减慢。__

## HDFS好处
__HDFS是将所有硬件磁盘虚拟化的一个大仓库。所以一个文件很有可能被分为几部分，分别存放在不同的物理磁盘上。但在HDFS这个层面上看到的还是一个完整的文件。这也就意味这文件的安全性得到了提高—HDFS的高容错和高回复在这里起到了至关重要的作用。同时HDFS中应该有正常空闲或专门用来备用的机器，这些用来在节点物理破坏后进行数据恢复和维持集群正常、保持负载均衡时使用。__

